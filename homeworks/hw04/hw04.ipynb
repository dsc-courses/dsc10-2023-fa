{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Simulation, Sampling, and Bootstrapping\n",
    "\n",
    "## Due Saturday, November 11th at 11:59PM\n",
    "\n",
    "Welcome to Homework 4! This homework will cover:\n",
    "- Simulations (see [CIT 9.3-9.4](https://inferentialthinking.com/chapters/09/3/Simulation.html))\n",
    "- Sampling and Empirical Distributions (see [CIT 10-10.4](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html))\n",
    "- Bootstrapping and Confidence Intervals (see [CIT 13.2](https://inferentialthinking.com/chapters/13/2/Bootstrap.html) and [CIT 13.3](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Remember to start early and submit often. You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (the schedule can be found [here](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it.\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lucky Triton Lotto, Continued  üî± üé± üßú\n",
    "\n",
    "In the last homework, we calculated the probability of winning the grand prize (free housing) on a Lucky Triton Lotto lottery ticket, and found that it was quite low üò≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "free_housing_chance = (1 / 28) * (1 / 27) * (1 / 26) * (1 / 25) * (1 / 24) * (1 / 11)\n",
    "free_housing_chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we'll approach the same question not using math, but using simulation. \n",
    "\n",
    "It's important to remember how this lottery works:\n",
    "- When you buy a Lucky Triton Lotto ticket, you first pick five **different** numbers, one at a time, from 1 to 28. Then you separately pick a number from 1 to 11, which may or may not be the same as one of the first five. These are **your numbers**. For example, you may select (7, 12, 24, 15, 13, 3). This is a sequence of six numbers - **order matters**!\n",
    "- The **winning numbers** are chosen by King Triton drawing five balls, one at a time, **without replacement**, from a pot of white balls numbered 1 to 28. Then, he draws a gold ball, the Tritonball, from a pot of gold balls numbered 1 to 11. Both pots are completely separate, hence the different ball colors. For example, maybe the winning numbers are (15, 9, 24, 23, 1, 3).\n",
    "\n",
    "We‚Äôll assume for this problem that in order to win the grand prize (free housing), all six of your numbers need to match the winning numbers and be in the **exact same positions**. In other words, your entire sequence of numbers must be exactly the same as the sequence of winning numbers. However, if some numbers in your sequence match up with the corresponding number in the winning sequence, you will still win some Triton Cash. \n",
    "\n",
    "Suppose again that your numbers are (7, 12, 24, 15, 13, 3) and the winning numbers are (15, 9, 24, 23, 1, 3). In this case, two of your numbers are considered to match two of the winning numbers. Notice that although both sequences include the number 15 within the first five numbers (representing a white ball), since they are in different positions, that's not considered a match.\n",
    "\n",
    "- Your numbers: (7, 12, **24**, 15, 13, **3**)\n",
    "- Winning numbers: (15, 9, **24**, 23, 1, **3**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Implement a function called `simulate_one_ticket`. It should take no arguments, and it should return an array with 6 random numbers, simulating how the numbers are selected for a single Lucky Triton Lotto ticket. The first five numbers should all be randomly chosen without replacement, from 1 to 28. The last number should be between 1 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_ticket():\n",
    "    \"\"\"Simulate one Lucky Triton Lotto ticket.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** It's draw day. You checked the winning numbers King Triton drew, which happened to be **(26, 19, 24, 5, 12, 7)**. Below, calculate how many matches there are between the winning numbers and a randomly generated ticket, and save the result in `num_matches`. Remember, order matters when counting matches!\n",
    "\n",
    "***Hint:*** You don't need a `for`-loop for this question. There is a one-line solution using `np.count_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([26, 19, 24, 5, 12, 7])\n",
    "simulated_ticket = simulate_one_ticket()\n",
    "num_matches = ...\n",
    "\n",
    "print(f\"The number of matches between the winning numbers {winning} and the simulated ticket {simulated_ticket} is {num_matches}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** You are disappointed because you bought a lottery ticket but you did not win free housing. To make yourself feel better, you write a simulation to remind yourself how unlikely it is to win the grand prize. \n",
    "\n",
    "Implement a simulation where you call the function `simulate_one_ticket` 100,000 times. In your 100,000 tickets, **how many times did you win the grand prize (free housing)?** Assign your answer to `count_free_housing`. (It would cost a fortune if you were to buy 100,000 tickets ‚Äì it's pretty nice to be able to simulate this experiment instead of doing it in real life!) \n",
    "\n",
    "***Hint:*** Start by writing a simulation where you only buy 10 tickets. Once you are sure you have that figured out, then ramp it up to 100,000 tickets. This is a good general practice for writing simulations: start small! It may take a little while (up to a minute) for Python to perform the calculations when you are buying 100,000 tickets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([26, 19, 24, 5, 12, 7])\n",
    "count_free_housing = ...\n",
    "...\n",
    "count_free_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the mathematical probability of winning free housing is quite low, on the order of $10^{-9}$. That's a lot lower than than 1 in 100,000, which is $10^{-5}$.\n",
    "\n",
    "**Question 1.4.** As we've seen, you would need to be extremely lucky to win the grand prize. To encourage more students to buy Lucky Triton Lotto tickets despite the terrible odds, there are some additional prizes. Students can win Triton Cash if *some* of their numbers match the corresponding winning numbers, as described in the introduction. Again, simulate the act of buying 100,000 tickets, but this time find **the greatest number of matches achieved by any of your tickets**, and assign this number to `most_matches`. \n",
    "\n",
    "For example, if 90,000 of your tickets matched 1 winning number and 10,000 of your tickets matched 2 winning numbers, then you would set `most_matches` to 2. If 99,999 of your tickets matched 1 winning number and one of your tickets matched 4 winning numbers, you would set `most_matches` to 4. If you happened to win the grand prize on one of your tickets, you would set `most_matches` to 6. \n",
    "\n",
    "***Hint:*** There are several ways to approach this; one way involves storing the number of matches per ticket in an array and finding the largest number in that array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([26, 19, 24, 5, 12, 7])\n",
    "most_matches = ...\n",
    "...\n",
    "most_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Suppose one Lucky Triton Lotto ticket costs $5.\n",
    "\n",
    "The Lucky Triton Lotto advertisement on Instagram promises you will never lose money because of the following generous prizes:\n",
    "\n",
    "- Win $10 with a 1-number match\n",
    "\n",
    "- Win $25 with a 2-number match\n",
    "\n",
    "- Win $100 with a 3-number match\n",
    "\n",
    "- Win $1,000 with a 4-number match\n",
    "\n",
    "- Win $5,000 with a 5-number match\n",
    "\n",
    "- Win $20,000 with a 6-number match (free housing!)\n",
    "\n",
    "If you had the money to buy 100,000 tickets, what would be your net winnings from buying these tickets? Since this is net winnings, this should account for the prizes you win and the cost of buying the tickets. Assign the amount to `net_winnings`. Note that a positive value means you won money overall, and a negative value means you lost money overall. Do you believe the advertisement's claims?\n",
    "\n",
    "The winning numbers are the same from the previous part: **(26, 19, 24, 5, 12, 7)**.\n",
    "\n",
    "***Hint:*** Again, there are a few ways you could approach this problem. One way involves generating another 100,000 random tickets and counting the amount earned per ticket, adding to a running total. Alternatively, if you created an array of the number of matches per ticket in Question 1.4, you could loop through that array. For practice, you can try solving this problem multiple ways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_winnings = ...\n",
    "...\n",
    "net_winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling with Netflix üçøüé¨\n",
    "\n",
    "In this question, we will use a dataset consisting of information about all Netflix Original movies to get some practice with sampling. Run the cell below to load the data into a DataFrame, indexed by title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "movie_data = bpd.read_csv('data/netflix_originals.csv').set_index('Title')\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a function called `compute_statistics` that takes as input a DataFrame with two columns, `'Runtime'` and `'IMDb Score'`, and then:\n",
    "- draws a histogram of `'Runtime'`,\n",
    "- draws a histogram of `'IMDb Score'`, and\n",
    "- returns a two-element array containing the mean `'Runtime'` and mean `'IMDb Score'`.\n",
    "\n",
    "Run the cell below to define the `compute_statistics` function, and a helper function called `histograms`. Don't worry about how this code works, and please don't change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it.\n",
    "def histograms(df):\n",
    "    runtimes = df.get('Runtime').values\n",
    "    ratings = df.get('IMDb Score').values\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=100)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(runtimes, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 250, 10))\n",
    "    plt.title('Distribution of Runtimes')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(ratings, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 10, 0.4))\n",
    "    plt.title('Distribution of IMDb Scores')\n",
    "    \n",
    "def compute_statistics(runtimes_and_ratings_data, draw=True):\n",
    "    if draw:\n",
    "        histograms(runtimes_and_ratings_data)\n",
    "    avg_runtime = np.average(runtimes_and_ratings_data.get('Runtime').values)\n",
    "    avg_rating = np.average(runtimes_and_ratings_data.get('IMDb Score').values)\n",
    "    avg_array = np.array([avg_runtime, avg_rating]) \n",
    "    return avg_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this `compute_statistics` function to show the distribution of `'Runtime'` and `'IMDb Score'` and compute their means, for any collection of movies. \n",
    "\n",
    "Run the next cell to show these distributions and compute the means for all Netflix Original movies. Notice that an array containing the mean `'Runtime'` and mean `'IMDb Score'` values is displayed before the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats = compute_statistics(movie_data)\n",
    "movie_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that instead of having access to the full *population* of movies, we only have access to data on a smaller subset of movies, or a *sample*.  For 584 movies, it's not so unreasonable to expect to see all the data, but usually we aren't so lucky.  Instead, we often make *statistical inferences* about a large underlying population using a smaller sample.\n",
    "\n",
    "**Statistical inference** is the process of using data in a sample to _infer_ some characteristic about the population from which the sample was drawn. A common strategy for statistical inference is to estimate parameters of the population by computing the same statistics on a sample. This strategy sometimes works well and sometimes doesn't.  The degree to which it gives us useful answers depends on several factors.\n",
    "\n",
    "One very important factor in the utility of samples is how they were gathered. Let's look at some different sampling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience sampling\n",
    "One sampling methodology, which is **generally a bad idea**, is to choose movies which are somehow convenient to sample.  For example, you might choose movies that you have personally watched, since it's easier to collect information about them.  This is called *convenience sampling*.\n",
    "\n",
    "**Question 2.1.**  Suppose your favorite types of movies are rom-coms ü•∞ and thrillers üò±, and you decide to manually look up information on all Netflix Original movies in the following genres:\n",
    "- `'Romantic comedy'`\n",
    "- `'Thriller'`\n",
    "\n",
    "Assign `convenience_sample` to a subset of `movie_data` that contains only the rows for movies that are in one of these two genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "convenience_sample = ...\n",
    "convenience_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Assign `convenience_stats` to an array of the mean `'Runtime'` and mean `'IMDb Score'` of your convenience sample.  Since they're computed on a sample, these are called *sample means*. \n",
    "\n",
    "***Hint:*** Use the function `compute_statistics`; it's okay if histograms are displayed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_stats = ...\n",
    "convenience_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the distribution of `'Runtime'` in our convenience sample to the distribution of `'Runtime'` for all the movies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "def compare_runtimes(first, second, first_title, second_title):\n",
    "    \"\"\"Compare the runtimes in two DataFrames.\"\"\"\n",
    "    bins = np.arange(0, 250, 10)\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=85)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(first.get('Runtime'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Runtimes ({first_title})')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(second.get('Runtime'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Runtimes ({second_title})')\n",
    "\n",
    "compare_runtimes(movie_data, convenience_sample, 'All Movies', 'Convenience Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** From what you see in the histograms above, did the convenience sample give us an accurate picture of the runtimes for the full population of movies?  Why or why not?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q3` below. \n",
    "1. Yes. The sample is large enough, so it is an accurate representation of the population.\n",
    "1. No. Convenience samples generally don't give us an accurate representation of the population.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but we just got unlucky.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but only if the sample size is large enough. Our convenience sample here was too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random sampling\n",
    "A more principled approach is to sample uniformly at random from the movies.  If we ensure that each movie is selected at most once, this is a **random sample without replacement**, sometimes called a \"**simple random sample**\" or \"**SRS**\".  Imagine writing down each movie's title on a card, putting the cards in a hat, and shuffling the hat.  To sample, pull out cards one by one and set them aside, stopping when the specified *sample size* is reached.\n",
    "\n",
    "We've produced two simple random samples of `ratings_data`: the variable `small_srs_data` contains a SRS of size 70, and the variable `large_srs_data` contains a SRS of size 180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the same analyses on the small simple random sample, the large simple random sample, and the convenience sample. The subsequent code draws the histograms and computes the means for `'Runtime'` and `'IMDb Score'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, but do run it.\n",
    "small_srs_data = bpd.read_csv('data/small_srs_rating.csv').set_index('Title')\n",
    "large_srs_data = bpd.read_csv('data/large_srs_rating.csv').set_index('Title')\n",
    "\n",
    "small_stats = compute_statistics(small_srs_data, draw=False);\n",
    "large_stats = compute_statistics(large_srs_data, draw=False);\n",
    "convenience_stats = compute_statistics(convenience_sample, draw=False);\n",
    "\n",
    "print('Full data stats:                 ', movie_stats)\n",
    "print('Small SRS stats:', small_stats)\n",
    "print('Large SRS stats:', large_stats)\n",
    "print('Convenience sample stats:        ', convenience_stats)\n",
    "\n",
    "color_dict = {\n",
    "    'small SRS': 'blue',\n",
    "    'large SRS': 'green',\n",
    "    'convenience sample': 'orange'\n",
    "}\n",
    "\n",
    "plt.subplots(3, 2, figsize=(15, 15), dpi=100)\n",
    "i = 1\n",
    "\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('Runtime'), density=True, alpha=0.5, color=color_dict[name], ec='w', \n",
    "             bins=np.arange(0, 250, 10))\n",
    "    plt.title(f'Runtimes ({name})');\n",
    "\n",
    "i = 2\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('IMDb Score'), density=True, alpha=0.5, color=color_dict[name], ec='w', \n",
    "             bins=np.arange(0, 10, 0.4))\n",
    "    plt.title(f'IMDb Ratings ({name})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing simple random samples\n",
    "Often it's useful to take random samples even when we have a larger dataset available.  One reason is that doing so can help us understand how inaccurate other samples are.\n",
    "\n",
    "As we saw in Lecture 14, DataFrames have a `.sample` method for producing simple random samples.  Note that its default is to sample **without** replacement, which aligns with how simple random samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Produce a simple random sample of size 70 from `movie_data`. Store an array containing the mean `'Runtime'` and mean `'IMDb Score'` of your SRS in `my_small_stats`. Again, it's fine if histograms are displayed.\n",
    "\n",
    "Remember, simple random samples are drawn _without_ replacement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_small_stats = ...\n",
    "my_small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell in which `my_small_stats` is defined many times, to collect new samples and compute their sample means.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, recall, `small_stats` is an array containing the mean `'Runtime'` and mean `'IMDb Score'` for the one small SRS that we provided you with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following two-fold question:\n",
    "- Are the values in `my_small_stats` (the mean `'Runtime'` and `'IMDb Score'` for **your** small SRS) similar to the values in `small_stats` (the mean `'Runtime'` and `'IMDb Score'` for the small SRS **we provided you with**)? \n",
    "- Each time you collect a new sample ‚Äì i.e. each time you re-run the cell where `my_small_stats` is defined ‚Äì do the values in `my_small_stats` change a lot?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q4` below.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and don't change at all each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are slightly different from the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are very different from the values in `small_stats`, and don't change at all each time a new sample is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Similarly, create a simple random sample of size 180 from `movie_data` and store an array of the sample's mean `'Runtime'` and mean `'IMDb Score'` in `my_large_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_large_stats = ...\n",
    "my_large_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell in which `my_large_stats` is defined many times. Do the histograms and  mean statistics (mean `'Runtime'` and mean `'IMDb Score'`) seem to change more or less across samples of size 180 than across samples of size 70?\n",
    "\n",
    "Assign either 1, 2, or 3 to the variable `sampling_q5` below. \n",
    "\n",
    "1. The statistics change *less* across samples of size 180 than across samples of size 70.\n",
    "1. The statistics change an *equal amount* across samples of size 180 and across samples of size 70.\n",
    "1. The statistics change *more* across samples of size 180 than across samples of size 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chocolate Shop  üç´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are planning to open a chocolate shop! To get a sense of the local residents' chocolate preferences, you survey 510 randomly-selected local residents and ask which type of chocolate they prefer the most among four options ‚Äì `'dark'`, `'milk'`, `'white'`, `'bittersweet'`. You also record some indecisive individuals as `'undecided'`.\n",
    "\n",
    "Run the next cell to load in the results of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = bpd.read_csv('data/chocolate.csv')\n",
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you're truly interested in, though, is the proportion of *all local residents* that prefer each type of chocolate. These are *population parameters* (plural, because there are five proportions).\n",
    "\n",
    "<center><img src=\"images/choco-pun.jpeg\" width=35%></center>\n",
    "\n",
    "Your friends tell you that dark chocolate is popular and that your shop should focus on dark chocolate-based creations. To make an informed decision, you decide to look at your survey data to determine the proportion of local residents that prefer `'dark'` chocolate over all other types of chocolate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Ideally, you want to determine the exact proportion of residents who prefer `'dark'` chocolate among all the local residents. However, it's not feasible to survey everyone in the area. Instead, you collected a sample of responses to obtain a ____________ statistic to estimate this ____________ parameter.\n",
    "\n",
    "Complete the sentence above by filling in the blanks. Set `q3_1` to 1 or 2.\n",
    "\n",
    "1. sample; population\n",
    "1. population; sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** Start by calculating the proportion of residents in your sample who prefer `'dark'` chocolate. Assign this value to `dark_proportion`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_proportion = ...\n",
    "dark_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Or are you? You have a single estimate for the true proportion of residents who prefer `'dark'` chocolate. However, you don't know how close that estimate is, or how much it could have varied if you'd had a different sample. In other words, you have an estimate, but no understanding of how close that estimate is to the true proportion of all local residents who prefer `'dark'` chocolate.\n",
    "\n",
    "This is where the idea of resampling via **[bootstrapping](https://inferentialthinking.com/chapters/13/2/Bootstrap.html)** comes in. Assuming that our sample resembles the population fairly well, we can resample from our original sample to produce more samples. From each of these resamples, we can produce another estimate for the true proportion of residents who prefer `'dark'` chocolate, which gives us a distribution of sample proportions that describes how the estimate might vary given different samples. We can then use this distribution to understand the variability in the estimated proportion of residents who prefer `'dark'` chocolate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Now, let's use bootstrapping to get a sense of the distribution of the sample proportion. Complete the following code to produce 1,000 bootstrapped estimates for the proportion of residents who prefer `'dark'` chocolate. Store your 1,000 estimates in an array named `boot_dark_proportions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boot_dark_proportions = ...\n",
    "for i in np.arange(1000):\n",
    "    resample = ...\n",
    "    resample_proportion = ...\n",
    "    boot_dark_proportions = ...\n",
    "boot_dark_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Using the array `boot_dark_proportions`, compute an approximate **95%** confidence interval for the true proportion of residents who prefer `'dark'` chocolate.  Compute the lower and upper ends of the interval, named `dark_lower_bound` and `dark_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_lower_bound = ...\n",
    "dark_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the true proportion of residents who prefer dark chocolate in the population:\\n[{:f}, {:f}]\".format(dark_lower_bound, dark_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.**\n",
    "Is it true that 95% of the population lies in the range `dark_lower_bound` to `dark_upper_bound`? Assign the variable `q3_5` to either `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.**\n",
    "Is it true that the proportion of residents in the populuation who prefer `'dark'` chocolate over the other chocolates is a random quantity with approximately a 95% chance of falling between `dark_lower_bound` and `dark_upper_bound`? Assign the variable `q3_6` to either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.**\n",
    "Suppose we were somehow able to produce 20,000 new samples, each one a uniform random sample of 510 residents taken directly from the population. For each of those 20,000 new samples, we create a 95% confidence interval for the proportion of residents who prefer `'dark'` chocolate. Roughly how many of those 20,000 intervals should we expect to actually contain the true proportion of the population? Assign your answer to the variable `how_many` below. It should be of type `int`, representing the *number* of intervals, not the proportion or percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "how_many = ...\n",
    "how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** We also created 90%, 96%, and 99% confidence intervals from one sample (shown below), but forgot to label which confidence intervals were which! Match the interval to the percent of confidence the interval represents and assign your choices (either 1, 2, or 3) to variables `ci_90`, `ci_96`, and `ci_99`, corresponding to the 90%, 96%, and 99% confidence intervals respectively.\n",
    "\n",
    "*Hint*: Drawing the confidence intervals out on paper might help you visualize them better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $[0.245, 0.325]$\n",
    "\n",
    "\n",
    "2. $[0.237,  0.331]$\n",
    "\n",
    "\n",
    "3. $[0.251, 0.318]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_90 = ...\n",
    "ci_96 = ...\n",
    "ci_99 = ...\n",
    "ci_90, ci_96, ci_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Based on the results in `survey`, it seems that `'dark'` chocolate is more popular than `'milk'` chocolate among residents. We would like to construct a range of likely values ‚Äì that is, a confidence interval ‚Äì for the difference in popularity, which we define as:\n",
    "\n",
    "$$\\text{(Proportion of residents who prefer dark chocolate)} - \\text{(Proportion of residents who prefer milk chocolate)}$$\n",
    "\n",
    "Create a function, `differences_in_resamples`, that creates **1000 bootstrapped resamples of the original survey data** in the `chocolate` DataFrame, computes the difference in proportions for each resample, and returns an array of these differences. Store your bootstrapped estimates in an array called `boot_differences` and plot a histogram of these estimates.\n",
    "\n",
    "***Hints:*** \n",
    "- Use your code from Question 3.3 as a starting point.\n",
    "- To plot your histogram, you'll first need to create a DataFrame with one column, whose entries are the values in `boot_differences`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "election_2"
   },
   "outputs": [],
   "source": [
    "def differences_in_resamples():\n",
    "    np.random.seed(55) # Ignore this, and don't change it. It's here to make sure you get the same answer we did.\n",
    "    ...\n",
    "\n",
    "boot_differences = ...\n",
    "\n",
    "# Plot a histogram of boot_differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** Compute an approximate 95% confidence interval for the difference in proportions. Assign the lower and upper bounds of the interval to `diff_lower_bound` and `diff_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_lower_bound = ...\n",
    "diff_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the difference in popularity between dark chocolate and milk chocolate:\\n[{:f}, {:f}]\".format(diff_lower_bound, diff_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.11.** In this question, you computed two 95% confidence intervals:\n",
    "- In Question 3.4, you found a 95% confidence interval for the proportion of residents who prefer `'dark'` chocolate among the four chocolate options. Let's call this the \"dark chocolate CI.\"\n",
    "- In Question 3.10, you found a 95% confidence interval for the difference between the proportion of residents who prefer `'dark'` chocolate and the proportion of residents who prefer `'milk'` chocolate. Let's call this the \"difference CI.\" \n",
    "\n",
    "Choose how to best fill in the blanks to describe the widths of these two confidence intervals. Set Set `q3_11` to either 1, 2, 3, or 4.\n",
    "\n",
    ">The dark chocolate CI is ________________________ than the difference CI because we have a ________________________ for a single unknown parameter than the difference between two unknown parameters.\n",
    "\n",
    "1. wider; more accurate guess\n",
    "1. narrower; more accurate guess\n",
    "1. wider; less accurate guess\n",
    "1. narrower; less accurate guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_11 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hotels in Europe ‚úàÔ∏è‚ùÑÔ∏è\n",
    "\n",
    "You and your friends are planning a vacation to Europe for winter break! You have been considering four cities to visit: Sarajevo (in Bosnia and Herzegovina), Zagreb (in Croatia), Belgrade (in Serbia), and Ljubljana (in Slovenia). Sadly, as college students, you have a limited budget and only want to spend one week, so it might be too short to visit all four cities.  In planning your trip, you are wondering which city has the cheapest hotels.\n",
    "\n",
    "For the four cities above, you gathered hotel data from [Booking.com](https://www.booking.com/), an online booking website for travel. The DataFrame `hotels` below contains a **sample** of all the hotels in the four cities above. Each row corresponds to a particular hotel. We have information on the `'Hotel name'`, the `'City'`, the `'Price (BAM)'` for a one night stay (in BAM, the [currency of Bosnia and Herzegovina](https://en.wikipedia.org/wiki/Bosnia_and_Herzegovina_convertible_mark)), the `'Hotel star rating'` from 1 to 5, and the `'Customer rating'` from 1 to 10 . Now it‚Äôs time to analyze the price and rating of hotels for each city!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = bpd.read_csv('data/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Let's start by determining the mean price for each city. Create a DataFrame called `city_means`, indexed by `'City'`, with one column called `'Price (BAM)'` that contains the mean price for that city, in the original currency. Sort `city_means` in descending order of `'Price (BAM)'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_means = ...\n",
    "city_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** One of your friends mentions they really want to go to Zagreb, being that it is the homeland of the necktie üëî! However, Zagreb seems to have the most expensive hotels based on the data we have access to. With that said, the data we have access to is only a sample of all hotels in four cities, and thus the mean price for Zagreb that we computed above is only a sample statistic, not a population parameter.\n",
    "\n",
    "Produce 1,000 bootstrapped estimates for the mean price of **all** hotels in the city of Zagreb. Store the estimates in the `zagreb_averages` array. Then, use the `zagreb_averages` array to calculate an approximate **99% confidence interval** for the true mean price. Assign the endpoints of your interval to `lower_bound` and `upper_bound`.\n",
    "\n",
    "***Hint:*** Make sure to query **before** resampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zagreb_averages = ...\n",
    "\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "# Display the estimates in a histogram.\n",
    "bpd.DataFrame().assign(Estimated_Average_Price=zagreb_averages).plot(kind='hist', density=True, ec='w', figsize=(10, 5), title=\"Zagreb\");\n",
    "plt.plot([lower_bound, upper_bound], [0, 0], color='gold', linewidth=10, label='99% confidence interval');\n",
    "\n",
    "# Don't change what's below (though you will need to copy and change it in 4.3).\n",
    "city_name = 'Zagreb'\n",
    "f'A 99% confidence interval for average hotel price in {city_name} is [{lower_bound}, {upper_bound}].'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** You want to create the same histogram above for the other three cities, and also calculate the corresponding confidence intervals, but repeating the process above three more times would be redundant. Let's try to generalize what we did in Question 4.2 to work for any city! \n",
    "\n",
    "Create a function called `ci_and_hist`, which takes in a city name as a string, and:\n",
    "1. **Plots the histogram** of 1,000 bootstrapped estimates for the city's mean hotel price.\n",
    "2. **Returns** a string describing the approximate 99% confidence interval for the city's mean hotel price, formatted in the same way as the string displayed for Zagreb in Question 4.2. \n",
    "\n",
    "***Notes:*** \n",
    "- Make sure your function both plots a histogram and **returns** a string. For example, `ci_and_hist('Ljubljana')` should return a string that starts with `'A 99% confidence interval for average hotel price in Ljubljana is'`. It's ok if you see the return string displayed before the plot.\n",
    "- The string displayed at the end of 4.2 was created using a feature of Python called f-strings. You'll need to copy and change that f-string expression. Read [this article](https://realpython.com/python-f-strings/#simple-syntax) for more details about f-strings if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_and_hist(city_name):\n",
    "    ...\n",
    "    \n",
    "# Example calls to the function. Don't change the lines below.\n",
    "ljubljana_string = ci_and_hist('Ljubljana')\n",
    "print(ljubljana_string)\n",
    "sarajevo_string = ci_and_hist('Sarajevo')\n",
    "print(sarajevo_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "5. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
