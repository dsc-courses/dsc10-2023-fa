{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing and Permutation Testing\n",
    "\n",
    "## Due Friday, December 1st at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This homework covers hypothesis testing ([CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)) and permutation testing ([CIT 12](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = 'https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000&rm=minimal'\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Was it by Random Chansey? üé≤\n",
    "\n",
    "<img src='images/chansey.png' width='250'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You recently decided to buy the video game *Pok√©mon Yellow* from someone on Ebay. The seller tells you that they've modified the game so that the probabilities of encountering certain Pok√©mon in certain locations have been altered. However, the seller doesn't tell you which specific locations have had their probability models changed and what they've been changed to.\n",
    "\n",
    "As you are playing *Pok√©mon Yellow*, you arrive at the Safari Zone, one of the most iconic locations in the game. You're curious as to your chances of encountering your favorite Pok√©mon, Chansey, in this location. You go onto [Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Kanto_Safari_Zone#Area_1) to find the probability model for this location, and you discover that for each Pok√©mon encounter in the Safari Zone, there is a 4% chance of encountering Chansey. \n",
    "\n",
    "After a few hours of gameplay in the Safari Zone, you have encountered Chansey **48 times out of 821** total Pok√©mon encounters (around 5.8%). You start to suspect that the Safari Zone may have been one of the locations in which the previous owner of the game changed the probability model.\n",
    "\n",
    "To test this, you decide to run a hypothesis test with the following hypotheses:\n",
    "\n",
    "**Null Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is 4%. \n",
    "\n",
    "**Alternative Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is greater than 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `one_simulation`, which has no arguments. It should randomly generate 821 Pok√©mon encounters in the Safari Zone and return the **proportion** of encountered Pok√©mon that were Chansey. \n",
    "\n",
    "***Hint:*** Use `np.random.multinomial`. You don't need a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulation():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** The test statistic for our hypothesis test will be the difference between the proportion of Chansey encounters in a given sample of 821 Safari Zone encounters and the expected proportion of Chansey encounters.\n",
    "\n",
    "$$\\text{test statistic} = \\text{proportion of Chansey encounters in sample} - 0.04$$\n",
    "\n",
    "Let's conduct 10,000 simulations. Create an array named `proportion_diffs` containing 10,000 simulated values of the test statistic described above. Utilize the function created in the previous question to perform this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_diffs = ...\n",
    "\n",
    "# Visualize with a histogram. Don't change anything below.\n",
    "bpd.DataFrame().assign(proportion_differences=proportion_diffs).plot(kind='hist', bins=20, density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=(48 / 821 - 0.04), color='black', linewidth=4, label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Calculate the p-value for this hypothesis test, and assign the result to `safari_zone_p`.\n",
    "\n",
    "***Hint:*** Do large values of our test statistic favor the alternative hypothesis, or do small values of our test statistic favor the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari_zone_p = ...\n",
    "safari_zone_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `safari_zone_conclusion`, corresponding to the best conclusion.\n",
    "\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say if the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari_zone_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** In this question, we chose as our test statistic the proportion of Chansey encounters in the Safari Zone minus 0.04. But this is not the only statistic we could have chosen; there are many that could have worked here. \n",
    "\n",
    "From the options below, choose the test statistic that would **not** have worked for this hypothesis test, and assign 1, 2, 3, or 4 to the variable `bad_choice`.\n",
    "\n",
    "1. The proportion of Chansey encounters in the Safari Zone.\n",
    "1. The number of Chansey encounters out of 821 enounters in the Safari Zone.\n",
    "1. The absolute difference between 0.04 and the proportion of Chansey encounters in the Safari Zone.\n",
    "1. 0.04 minus the proportion of Chansey encounters in the Safari Zone.\n",
    "\n",
    "***Hint:*** Our goal is to find a test statistic that will help us determine whether we encounter Chansey **more** often than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_choice = ...\n",
    "bad_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <span> Mystery Box</span> üéÅ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/subway_surfers.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subway Surfers is an \"endless runner\" mobile game where the player controls a character that continually runs forward along a subway track. The player tries to dodge obstacles and collect rewards along the way, all while avoiding train collisions and being caught by the subway inspector. One of the rewards is a Mystery Box which contains one of several possible prizes.\n",
    "\n",
    "<img src='images/mystery_box.png' width='600'>\n",
    "\n",
    "There are four types of prizes in a Mystery Box: `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`. The most valuable is the `'Jackpot'` ü§© but it's also the most rare. Unfortunately, there is no publicly available information on the exact probabilities of getting any of the four types of prizes in a Mystery Box. However, Mert plays Subway Surfers a lot, and based on his experience with the game, he proposes the following probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Mert's Estimated Probability|\n",
    "| --- | --- |\n",
    "| Jackpot | $0.02$ |\n",
    "| Rare | $0.10$ |\n",
    "| Special | $0.25$ |\n",
    "| Common | $0.63$ |\n",
    "\n",
    "We'll store this distribution in an array, in the order `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "mert_dist = np.array([0.02, 0.1, 0.25, 0.63])\n",
    "mert_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the validity of Mert's model, you collect data from many Subway Surfers players. You learn that in total, out of 2,902 Mystery Box prizes:\n",
    "- 43 were `'Jackpot'`,\n",
    "- 329 were `'Rare'`,\n",
    "- 667 were `'Special'`, and\n",
    "- the rest were `'Common'`.\n",
    "\n",
    "You then calculate the **empirical** type distribution using the data you collected and store it in an array as well (in the same order as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "empirical_dist = np.array([43, 329, 667, 2902 - (43 + 329 + 667)]) / 2902\n",
    "empirical_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `empirical_dist` is not identical to `mert_dist`, it's still possible that Mert's model is plausible, and that the observed differences are due to random chance. Let's run a hypothesis test to investigate further, using the following hypotheses: \n",
    "\n",
    "**Null Hypothesis**: The types of Mystery Box prizes are drawn randomly from the distribution `mert_dist`.\n",
    "\n",
    "**Alternative Hypothesis**: The types of Mystery Box prizes are _not_ drawn randomly from the distribution `mert_dist`.\n",
    "\n",
    "Note that this hypothesis test involves four proportions ‚Äì one for each of `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`.\n",
    "\n",
    "**Question 2.1.**  Which of the following is **not** a reasonable choice of test statistic for this hypothesis test? Assign 1, 2, or 3 to the variable `unreasonable_test_statistic`. \n",
    "1. The absolute difference between the sum of the proposed distribution (Mert's expected proportion of types) and the sum of the empirical distribution (actual proportion of types).\n",
    "1. The sum of the absolute difference between the proposed distribution (Mert's expected proportion of types) and the empirical distribution (actual proportion of types).\n",
    "1. Among all four prize types, the largest absolute difference between Mert's expected proportion and the actual proportion of prizes of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreasonable_test_statistic = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** We'll use the TVD, i.e. **total variation distance**, as our test statistic. Below, complete the implementation of the function `total_variation_distance`, which takes in two distributions (stored as arrays) as arguments and returns the total variation distance between the two arrays.\n",
    "\n",
    "Then, use the function `total_variation_distance` to determine the TVD between the type distribution proposed by Mert and the empirical type distribution you observed. Assign this TVD to `observed_tvd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(first_distrib, second_distrib):\n",
    "    '''Computes the total variation distance between two distributions.'''\n",
    "    ...\n",
    "\n",
    "observed_tvd = ...\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now, we'll calculate 5,000 simulated TVDs to see what a typical TVD between the proposed distribution and an empirical distribution would look like if Mert's model were accurate. Since our real-life data includes 2,902 Mystery Box prizes, in each trial of the simulation, we'll:\n",
    "- draw 2,902 Mystery Boxes at random from Mert's proposed distribution, then \n",
    "- calculate the TVD between **Mert's proposed type distribution** and the **empirical type distribution from the simulated sample**. \n",
    "\n",
    "Store these 5,000 simulated TVDs in an array called `simulated_tvds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulated_tvds = ...\n",
    "\n",
    "# Visualize the distribution of TVDs with a histogram\n",
    "bpd.DataFrame().assign(simulated_tvds=simulated_tvds).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=observed_tvd, color='black', linewidth=4, label='observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Now, determine the p-value for our test by finding the proportion of times in our simulation that we saw a TVD greater than or equal to our observed TVD. Assign your result to `subway_surfers_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subway_surfers_p = ...\n",
    "subway_surfers_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `subway_surfers_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say if the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_surfers_conclusion = ...\n",
    "subway_surfers_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python vs Java üêç‚òï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stack Overflow](https://stackoverflow.com/) is a forum where users can ask and answer questions about code. (If you've never used it before, it is a great resource!)\n",
    "\n",
    "In this section, we'll work with a dataset of Stack Overflow questions from 2016 to 2020, downloaded from [Kaggle](https://www.kaggle.com/datasets/imoore/60k-stack-overflow-questions-with-quality-rate?resource=download&select=train.csv). The data has been cleaned and condensed for the purposes of this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains six columns: `'Id'`, `'Title'`, `'Body'`, `'Tags'`, `'CreationDate'`, `'Rating'`. Let's read it in and store it as a DataFrame named `stack_overflow`.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| `'Id'` | ID of the question |\n",
    "| `'Title'` | Title of the question |\n",
    "| `'Body'` | Description of the question |\n",
    "| `'Tags'` | Tags used to categorize question |\n",
    "| `'CreationDate'` | Date the question was asked |\n",
    "| `'Rating'` | Quality rating of the post |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_overflow = bpd.read_csv('data/stack_overflow.csv')\n",
    "stack_overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.**\n",
    "Each post is given a quality rating. **We're interested in exploring whether Python posts have higher ratings than Java posts.**\n",
    "\n",
    "To determine whether a post is about Python or Java, we can look in the `'Tags'` column. The values in the `'Tags'` column contain several tags that are used to categorize posts. One of the tags for each post will be the programming language the post is about ‚Äì for instance, in row 2 above, one of the tags for the post is `'<python>'`.\n",
    "\n",
    "Below, assign `python_java` to a DataFrame that only contains questions that used the tags `'<python>'` or `'<java>'`. Don't worry about capitalization as all the tags have already been lowercased. Note that these questions may include other tags as well. \n",
    "\n",
    "***Hints:*** \n",
    "- Use `str.contains`.\n",
    "- There is a `'<javascript>'` tag, but that's not the same as the `'<java>'` tag, as JavaScript and Java are different programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python_java = ...\n",
    "python_java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further investigation, it looks like there are some posts that contain both the tags `'<python>'` and `'<java>'`. For the purposes of answering our question, we only want posts that have `'<python>'` or `'<java>'`, but not both. We've gone ahead and removed the posts that contained both tags and saved the resulting DataFrame to `fixed_python_java`, which you should use in Question 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "fixed_python_java = python_java[python_java.get('Tags').str.contains('<python>') & python_java.get('Tags').str.contains('<java>') == False]\n",
    "fixed_python_java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** As we have seen, posts can be associated with multiple tags, but the only piece of information in the `'Tags'` column we're interested in is whether the language of the post is Python or Java.\n",
    "\n",
    "Complete the implementation of the function `simplify_tag`, which takes in a string of tags associated with a single post and returns either `'Python'` or `'Java'`. \n",
    "\n",
    "Once you've done that, use your function to help you create a new DataFrame named `with_language` that has all the same columns as `fixed_python_java`, in the same order, with an additional column named `'Language'` that contains the programming language associated with the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_tag(tag): \n",
    "    ...\n",
    "    \n",
    "with_language = ...\n",
    "with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** As a reminder, we're interested in exploring whether Python posts have higher ratings than Java posts. In order to do that, we need to have ratings in the form of numbers, but right now, the `'Rating'` column contains categorical values. The [Kaggle](https://www.kaggle.com/datasets/imoore/60k-stack-overflow-questions-with-quality-rate?resource=download&select=train.csv) page describes these values as follows: \n",
    "\n",
    "- `'HQ'`: High-quality posts without a single edit.\n",
    "- `'LQ_EDIT'`: Low-quality posts with a negative score, and multiple community edits. However, they still remain open after those changes.\n",
    "- `'LQ_CLOSE'`: Low-quality posts that were closed by the community without a single edit.\n",
    "\n",
    "We're going to assign a numerical rating of `1` to low-quality posts that were closed (`'LQ_CLOSE'`), `2` to low-quality posts that remained open after edits ( `'LQ_EDIT'`) and `3` to high-quality posts (`'HQ'`).\n",
    "\n",
    "Complete the implementation of the function `numerical_rating`, which takes in a **string** from the `'Rating'` column and returns the corresponding numerical rating as described above. Once you've implemented `numerical_rating`, use it to **replace** the values in the `'Rating'` column of `with_language` with the corresponding numerical ratings.\n",
    "\n",
    "***Note:*** Our implementation of `numerical_rating` used only two lines of code, and one of the lines involved defining a dictionary. You don't have to use a dictionary in your implementation, but doing so will help keep your code concise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerical_rating(rating):\n",
    "    ...\n",
    "\n",
    "with_language = ...\n",
    "with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Using the DataFrame `with_language`, calculate the difference between the **mean** `'Rating'` of Python posts and Java posts. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean Python post rating} - \\text{mean Java post rating}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** What does the number you obtained for `observed_difference` mean? Assign `interpretation` to 1, 2, 3, or 4, corresponding to the best explanation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our sample, the mean Python post rating is higher than the mean Java post rating by about 18 percent.\n",
    "1. In our sample, the mean Python post rating is higher than the mean Java post rating by about 0.18 percent.\n",
    "1. In our sample, the mean Python post rating is higher than the mean Java post rating by about 0.18 points.\n",
    "1. In our sample, the mean Java post rating is higher than the mean Python post rating by about 18 percent.\n",
    "1. In our sample, the mean Java post rating is higher than the mean Python post rating by about 0.18 percent.\n",
    "1. In our sample, the mean Java post rating is higher than the mean Python post rating by about 0.18 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we want to conduct a permutation test to see if it is by chance that the average rating for Python posts is higher than the average rating of Java posts in our sample, or if Python posts actually have a higher rating on average than Java posts.\n",
    "\n",
    "- **Null Hypothesis**: The ratings of Python posts and Java posts come from the same distribution.  \n",
    "- **Alternative Hypothesis**: The ratings of Python posts are higher on average than the ratings of Java posts.\n",
    "\n",
    "**Question 3.6.** Assign `reduced_df` to a DataFrame with only two columns, `'Language'` and `'Rating'`, since these are the only relevant columns in `with_language` for this permutation test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = ...\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** To perform the permutation test, 1000 times, create two random groups by shuffling the `'Language'` column of `reduced_df`. Be sure not to shuffle the `'Rating'` column. For each pair of random groups, calculate the difference in mean rating (Python minus Java) and store your 1000 differences in the `differences` array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Compute a p-value for this hypothesis test and assign your answer to `stack_overflow_p`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_p = ...\n",
    "stack_overflow_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Assign the variable `stack_overflow_conclusion` to a **list** of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We accept the null hypothesis at the 0.01 significance level.\n",
    "1. We reject the null hypothesis at the 0.01 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "1. We accept the null hypothesis at the 0.05 significance level.\n",
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** Suppose in this question you had shuffled the `'Rating'` column instead and kept the `'Language'` column in the same order. Assign `shuffled_rating` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "\n",
    "1. The new p-value from shuffling `'Rating'` would be $1 - p$, where $p$ is the old p-value from shuffling `'Language'` (i.e. your answer to Question 3.8).\n",
    "1. We would need to change our null hypothesis in order to shuffle the `'Rating'` column. \n",
    "1. There would be no difference in the conclusion of the test if we had shuffled the `'Rating'` column instead.\n",
    "1. The `'Rating'` column cannot be shuffled because it contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_rating = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.11.** Which of the following choices best describes the purpose of shuffling one of the columns in our dataset in a permutation test? Assign `why_shuffle` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "1. Shuffling mitigates noise in our data by generating new permutations of the data.\n",
    "1. Shuffling is a special case of bootstrapping and allows us to produce interval estimates.\n",
    "1. Shuffling allows us to generate new data under the null hypothesis, which we can use in testing our hypothesis.\n",
    "1. Shuffling allows us to generate new data under the alternative hypothesis, which explains that the data come from different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "why_shuffle = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Battery Life üîãüéß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You and your friend are studying together for a final. Since both of you focus better when listening to music, you  challenge yourselves to study uninterrupted until each of your earbuds run out of battery. You own a pair of _Apple AirPods_ (i.e., AirPods) and your friend owns a pair of _Samsung Galaxy Buds Pro_ (i.e., Galaxy Buds). You both put on your earbuds and get to work.\n",
    "\n",
    "At the end of the study session, you find that your AirPods, which were fully charged at the start, lasted 4 hours and 18 minutes, while your friend's Galaxy Buds, also fully charged at the start, lasted 4 hours and 41 minutes. Intrigued by the noticeable difference in battery life between the two earbuds, you decide to investigate further. You make a post on Reddit asking people who have AirPods or Galaxy Buds to record how long their earbuds last on a single charge. You're overwhelmed by the amazing response and receive 80 different comments in total from other people, 40 from people with AirPods and 40 from people with Galaxy Buds.\n",
    "\n",
    "Let's look at all the data that you crowdsourced. Each entry in the `'BatteryLife'` column represents the amount of time that a pair of earbuds lasted on a full charge, in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_life_data = bpd.read_csv('data/earbuds.csv')\n",
    "battery_life_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Now let's address the question: how does the average battery life of Galaxy Buds compare to that of AirPods? Create a DataFrame called `galaxy` that contains only the battery life data for Galaxy Buds, and set `galaxy_mean` to the mean battery life of Galaxy Buds. Similarly, create a DataFrame `airpods` for AirPods and compute `airpods_mean`. Finally, set `observed_diff_mean`, to the difference in mean battery life of Galaxy Buds and AirPods in our sample, computed as follows.\n",
    "\n",
    "$$\\text{difference} = \\text{mean battery life of Galaxy Buds} - \\text{mean battery life of AirPods}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = ...\n",
    "airpods = ...\n",
    "galaxy_mean = ...\n",
    "airpods_mean = ...\n",
    "observed_diff_mean = ...\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you answered Question 4.1 correctly, you should have noticed a difference in the average battery life between Galaxy Buds and AirPods. But remember, we are only analyzing samples of size 40 for each brand. Would we observe such a difference in battery life if we had access to the entire population ‚Äì that is, all units ever produced by both brands ‚Äì or is it possible that this difference is merely a result of the specific samples we happened to collect? Let's do a **hypothesis test** to find out. We'll state our hypotheses as follows:\n",
    "\n",
    "- **Null Hypothesis**: The average battery life of Galaxy Buds is equal to that of AirPods. In other words, the difference in average battery life between the two brands equals 0 minutes.\n",
    "\n",
    "- **Alternative Hypothesis**: The average battery life of Galaxy Buds is not equal to that of AirPods. Hence, the difference in average battery life between the two brands is not 0 minutes.\n",
    "\n",
    "\n",
    "Since we are able to frame our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in average battery life between Galaxy Buds and AirPods ‚Äì is equal to a specific value, we can **test our hypotheses by constructing a confidence interval** for this parameter. For a refresher on this method, refer to [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html) or the human body temperature example from [Lecture 22](https://dsc10.com/resources/lectures/lec22/lec22.html).\n",
    "\n",
    "***Note:*** We are **not** conducting a permutation test here, although that would also be a valid approach to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Compute 1000 **bootstrapped estimates** for the difference in average battery life between Galaxy Buds and AirPods. As in Question 4.1, calculate the difference as Galaxy Buds minus AirPods. Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "You should generate your Galaxy Buds resamples by sampling from `galaxy`, and your AirPods resamples by sampling from `airpods`. Do not use the combined dataset `battery_life_data` for this task, otherwise you might not wind up with 40 of each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_means = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize your estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w', bins=20, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Compute a 95% confidence interval for the difference in mean battery life of AirPods and Galaxy Buds (as before, in the order Galaxy Buds minus AirPods). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print('Bootstrapped 95% confidence interval for the mean difference in battery life of AirPods and Galaxy Buds:\\n [{:f}, {:f}]'.format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.** What if all the people who responded to your original Reddit post had provided their battery lives in hours instead of minutes? Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
