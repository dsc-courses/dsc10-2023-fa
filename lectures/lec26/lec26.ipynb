{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code,\n",
    "# but make sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def standard_units(any_numbers):\n",
    "    \"Convert a sequence of numbers to standard units.\"\n",
    "    return (any_numbers - any_numbers.mean()) / np.std(any_numbers)\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"Return a DataFrame in which all columns of df are converted to standard units.\"\"\"\n",
    "    df_su = bpd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        df_su = df_su.assign(**{column + ' (su)': standard_units(df.get(column))})\n",
    "    return df_su\n",
    "\n",
    "def correlation(df, x, y):\n",
    "    '''Computes the correlation between column x and column y of df.'''\n",
    "    return (standard_units(df.get(x)) * standard_units(df.get(y))).mean()\n",
    "\n",
    "def slope(df, x, y):\n",
    "    '''Returns the slope of the regression line between columns x and y in df (in original units).'''\n",
    "    r = correlation(df, x, y)\n",
    "    return r * np.std(df.get(y)) / np.std(df.get(x))\n",
    "\n",
    "def intercept(df, x, y):\n",
    "    '''Returns the intercept of the regression line between columns x and y in df (in original units).'''\n",
    "    return df.get(y).mean() - slope(df, x, y) * df.get(x).mean()\n",
    "\n",
    "# All of the following code is for visualization.\n",
    "def plot_regression_line(df, x, y, margin=.02, alpha=1):\n",
    "    '''Computes the slope and intercept of the regression line between columns x and y in df (in original units) and plots it.'''\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    \n",
    "    df.plot(kind='scatter', x=x, y=y, s=50, figsize=(10, 5), label='original data', alpha=alpha)\n",
    "    left = df.get(x).min()*(1 - margin)\n",
    "    right = df.get(x).max()*(1 + margin)\n",
    "    domain = np.linspace(left, right, 10)\n",
    "    plt.plot(domain, m*domain + b, color='orange', label='regression line', lw=4)\n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.legend();\n",
    "\n",
    "def format_equation(m, b):\n",
    "    if b > 0:\n",
    "        return r'$y = %.2fx + %.2f$' % (m, b)\n",
    "    elif b == 0:\n",
    "        return r'$y = %.2fx' % m\n",
    "    else:\n",
    "        return r'$y = %.2fx %.2f$' % (m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 26 ‚Äì Residuals and Inference\n",
    "\n",
    "## DSC 10, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- The Final Project is due **tomorrow at 11:59PM**.\n",
    "    - You can use slip days if needed.\n",
    "    - If one or both partners has run out of slip days and you submit the project late, we will reallocate slip days towards the final project, away from lesser-weighted assignments. See the [syllabus](https://dsc10.com/syllabus/#deadlines-and-slip-days) for more details.\n",
    "- The Final Exam is **this Saturday from 7-10PM**. Read more details [here](https://edstem.org/us/courses/38383/discussion/3181148).\n",
    "- If at least 80% of the class fills out both [CAPEs](https://cape.ucsd.edu) and the [End-of-Quarter Survey](https://docs.google.com/forms/d/e/1FAIpQLSefDOyTsn4b9poc3I5iCbgdtXAnMnAxIjuiyHt5PHwpYoMIlg/viewform), then the entire class gets 0.5% of extra credit on their overall grade. We value your feedback!\n",
    "- The application to be a DSC 10 tutor in the fall has been released! The application can be found [here](https://academicaffairs.ucsd.edu/Modules/ASES/Apply.aspx?cid=5210), and more information can be found [here](https://datascience.ucsd.edu/current-students/dsc-tutors/).\n",
    "- **Today is the last day of new material. The next two days are for review!**\n",
    "    - Before Wednesday's lecture, work through the [Winter 2023 Final Exam](https://practice.dsc10.com/wi23-final).\n",
    "    - [This post on Ed](https://edstem.org/us/courses/38383/discussion/3183737) contains brand-new review materials prepared by tutors. Use them while studying!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Residuals.\n",
    "- Inference for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quality of fit\n",
    "\n",
    "- The regression line describes the \"best linear fit\" for a given dataset.\n",
    "- The formulas for the slope and intercept work no matter what the shape of the data is.\n",
    "- However, the line is only meaningful if the relationship between $x$ and $y$ is roughly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Non-linear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "x2 = bpd.DataFrame().assign(\n",
    "    x=np.arange(-6, 6.1, 0.5) + np.random.normal(size=25), \n",
    "    y=np.arange(-6, 6.1, 0.5)**2 + np.random.normal(size=25)\n",
    ")\n",
    "plot_regression_line(x2, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line doesn't fit the data at all, despite being the \"best\" line for the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Any set of predictions has _errors_.\n",
    "\n",
    "$$\\text{error} = \\text{actual } y - \\text{predicted } y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- When using the regression line to make predictions, the errors are called **residuals**.\n",
    "     \n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There is one residual corresponding to each data point $(x, y)$ in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predicted(df, x, y):\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    return m * df.get(x) + b\n",
    "\n",
    "def residual(df, x, y):\n",
    "    return df.get(y) - predicted(df, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting a son's height from his mother's height  üëµüë® üìè\n",
    "\n",
    "Is the association between `'mom'` and `'son'` linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If there is a linear association, is it strong?\n",
    "    - We can answer this using the correlation coefficient.\n",
    "    - Close to 0 = weak, close to -1/+1 = strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is \"linear\" the best description of the association between `'mom'` and `'son'`?\n",
    "    - **We'll use residuals to answer this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "galton = bpd.read_csv('data/galton.csv')\n",
    "\n",
    "male_children = galton[galton.get('gender') == 'male']\n",
    "mom_son = bpd.DataFrame().assign(mom = male_children.get('mother'), \n",
    "                                 son = male_children.get('childHeight'))\n",
    "\n",
    "mom_son_predictions = mom_son.assign(\n",
    "    predicted=predicted(mom_son, 'mom', 'son'),\n",
    "    residuals=residual(mom_son, 'mom', 'son'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_regression_line(mom_son_predictions, 'mom', 'son')\n",
    "\n",
    "idx = np.random.randint(0, mom_son_predictions.shape[0], size=50)\n",
    "for i, k in enumerate(idx):\n",
    "    x = mom_son_predictions.get('mom').iloc[k]\n",
    "    y = mom_son_predictions.get('son').iloc[k]\n",
    "    p = mom_son_predictions.get('predicted').iloc[k]\n",
    "    plt.plot([x,x], [y,p], linewidth=3, color='purple', label='residuals' if i == 0 else None)\n",
    "plt.legend();\n",
    "print('Correlation:', correlation(mom_son, 'mom', 'son'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The residual plot of a regression line is the scatter plot with the $x$ variable on the $x$-axis and residuals on the $y$-axis.\n",
    "\n",
    "    $$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Residual plots describe how the error in the regression line's predictions varies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: If a linear fit is good, the residual plot should look like a patternless \"cloud\" ‚òÅÔ∏è.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_son_predictions.plot(kind='scatter', x='mom', y='residuals', s=50, c='purple', figsize=(10, 5), label='residuals')\n",
    "plt.axhline(0, linewidth=3, color='k', label='y = 0')\n",
    "plt.title('Residual plot for predicting son\\'s height based on mother\\'s height')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The residual plot for a non-linear association üöó\n",
    "- Consider the hybrid cars dataset from earlier. \n",
    "- Let's look at a regression line that uses `'mpg'` to predict `'price'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid = bpd.read_csv('data/hybrid.csv')\n",
    "mpg_price = hybrid.assign(\n",
    "    predicted=predicted(hybrid, 'mpg', 'price'),\n",
    "    residuals=residual(hybrid, 'mpg', 'price')\n",
    ")\n",
    "mpg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line.\n",
    "plot_regression_line(hybrid, 'mpg', 'price');\n",
    "print('Correlation:', correlation(hybrid, 'mpg', 'price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot.\n",
    "mpg_price.plot(kind='scatter', x='mpg', y='residuals', figsize=(10, 5), s=50, color='purple', label='residuals')\n",
    "plt.axhline(0, linewidth=3, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between mpg and price')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that as `'mpg'` increases, the residuals go from being mostly large, to being mostly small, to being mostly large again. That's a pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue: Patterns in the residual plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Patterns in the residual plot imply that the relationship between $x$ and $y$ may not be linear.\n",
    "    - While this can be spotted in the original scatter plot, it may be easier to identify in the residual plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In such cases, a curve may be a better choice than a line for prediction.\n",
    "    - In future courses, you'll learn how to extend linear regression to work for polynomials and other types of mathematical functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another example: `'mpg'` and `'acceleration'` ‚õΩ\n",
    "\n",
    "- Let's fit a regression line that predicts `'mpg'` given `'acceleration'`.\n",
    "- Let's then look at the resulting residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_mpg = hybrid.assign(\n",
    "    predicted=predicted(hybrid, 'acceleration', 'mpg'),\n",
    "    residuals=residual(hybrid, 'acceleration', 'mpg')\n",
    ")\n",
    "accel_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line.\n",
    "plot_regression_line(accel_mpg, 'acceleration', 'mpg')\n",
    "print('Correlation:', correlation(accel_mpg, 'acceleration', 'mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot.\n",
    "accel_mpg.plot(kind='scatter', x='acceleration', y='residuals', figsize=(10, 5), s=50, color='purple', label='residuals')\n",
    "plt.axhline(0, linewidth=3, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between acceleration and mpg')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the residuals tend to vary more for smaller accelerations than they do for larger accelerations ‚Äì that is, the vertical spread of the plot is **not** similar at all points on the $x$-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue: Uneven vertical spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the vertical spread in a residual plot is uneven, it implies that the regression line's predictions aren't equally reliable for all inputs.\n",
    "    - This doesn't necessarily mean that fitting a non-linear curve would be better; it just impacts how we interpret the regression line's predictions.\n",
    "    - For instance, in the previous plot, we see that the regression line's predictions for cars with larger accelerations are more reliable than those for cars with lower accelerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The formal term for \"uneven spread\" is **heteroscedasticity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Anscombe's quartet\n",
    "\n",
    "<center><img src='images/anscombe.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- All 4 datasets have the same mean of $x$, mean of $y$, SD of $x$, SD of $y$, and correlation.\n",
    "    - Therefore, they have the same regression line because the slope and intercept of the regression line are determined by these 5 quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But they all look very different! Not all of them contain linear associations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: The Datasaurus Dozen ü¶ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino = bpd.read_csv('data/Datasaurus_data.csv')\n",
    "dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(dino, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope(dino, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept(dino, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(dino, 'x', 'y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Takeaway**: Never trust summary statistics alone; always visualize your data!\n",
    "\n",
    "<center><img src='images/datasaurus.png' width=800><br>(<a href=https://cran.r-project.org/web/packages/datasauRus/vignettes/Datasaurus.html>source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another perspective on regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What we're really doing:\n",
    "    - Collecting a sample of data from a population.\n",
    "    - Fitting a regression line to that sample.\n",
    "    - Using that regression line to make predictions for inputs that are not in our sample (e.g. for mothers whose sons we don't know the heights of)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What if we used a different sample? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concept Check ‚úÖ ‚Äì Answer at [cc.dsc10.com](http://cc.dsc10.com) \n",
    "\n",
    "What strategy will help us assess how different our regression line's predictions would have been if we'd used a different sample?\n",
    "\n",
    "- A. Hypothesis testing\n",
    "- B. Permutation testing\n",
    "- C. Bootstrapping\n",
    "- D. Central Limit Theorem\n",
    "\n",
    "Don't scroll pass this point without answering!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction intervals\n",
    "\n",
    "We want to come up with a range of reasonable values for a prediction for a single input $x$. To do so, we'll:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Bootstrap the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Compute the slope and intercept of the regression line for that sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Repeat steps 1 and 2 many times to compute many slopes and many intercepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. For a given $x$, use the bootstrapped slopes and intercepts to create bootstrapped predictions, and take the middle 95% of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The resulting interval will be called a **prediction interval**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping the scatter plot of mother/son heights\n",
    "\n",
    "Note that each time we run this cell, the resulting line is slightly different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Resample the dataset.\n",
    "resample = mom_son.sample(mom_son.shape[0], replace=True)\n",
    "\n",
    "# Step 2: Compute the slope and intercept of the regression line for that resample.\n",
    "plot_regression_line(resample, 'mom', 'son', alpha=0.5)\n",
    "\n",
    "plt.ylim([60, 80])\n",
    "plt.xlim([57, 72]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping predictions: mother/son heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig = slope(mom_son, 'mom', 'son')\n",
    "b_orig = intercept(mom_son, 'mom', 'son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_slopes = np.array([])\n",
    "boot_intercepts = np.array([])\n",
    "\n",
    "for i in np.arange(5000):\n",
    "    # Step 1: Resample the dataset.\n",
    "    resample = mom_son.sample(mom_son.shape[0], replace=True)\n",
    "    \n",
    "    # Step 2: Compute the slope and intercept of the regression line for that resample.\n",
    "    m = slope(resample, 'mom', 'son')\n",
    "    b = intercept(resample, 'mom', 'son')\n",
    "    boot_slopes = np.append(boot_slopes, m)\n",
    "    boot_intercepts = np.append(boot_intercepts, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### If a mother is 68 inches tall, how tall do we predict her son to be?\n",
    "\n",
    "Using the original dataset, and hence the original slope and intercept, we get a single prediction for the input of 68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orig = m_orig * 68 + b_orig\n",
    "pred_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the bootstrapped slopes and intercepts, we get an **interval** of predictions for the input of 68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_preds = boot_slopes * 68 + boot_intercepts\n",
    "boot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.percentile(boot_preds, 2.5)\n",
    "r = np.percentile(boot_preds, 97.5)\n",
    "[l, r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(\n",
    "    predictions=boot_preds\n",
    ").plot(kind='hist', density=True, bins=20, figsize=(10, 5), ec='w', title='Interval of predicted heights for the son of a 68 inch tall mother')\n",
    "plt.plot([l,r],[0.01,0.01], c='gold', linewidth=10, zorder=1, label='95% prediction interval')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How different could our prediction have been, for all inputs?\n",
    "\n",
    "Here, we'll plot several of our bootstrapped lines. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Don't worry about the code for this.\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(50, 80)\n",
    "ys = []\n",
    "for i, (m, b) in enumerate(zip(boot_slopes[:50], boot_intercepts)):\n",
    "    ys.append(m * x + b)\n",
    "    fig = plt.plot(x, m * x + b, linewidth=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Observations**:\n",
    "- All bootstrapped lines pass through $$(\\text{mean mother's height in resample}, \\text{mean son's height in resample})$$\n",
    "- Predictions seem to vary more for very tall and very short mothers than they do for mothers with an average height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction interval width vs. mother's height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about how this code works.\n",
    "def pred_interval(mom):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = np.arange(50, 80)\n",
    "    ys = []\n",
    "    for i, (m, b) in enumerate(zip(boot_slopes[:50], boot_intercepts)):\n",
    "        ys.append(m * x + b)\n",
    "        plt.plot(x, m * x + b, linewidth=1, alpha=0.1)  \n",
    "        \n",
    "    boot_preds = boot_slopes * mom + boot_intercepts\n",
    "    l = np.percentile(boot_preds, 2.5)\n",
    "    r = np.percentile(boot_preds, 97.5)\n",
    "    plt.plot([mom, mom], [l, r], linewidth=5, color='#eb7e35', label='95% prediction interval')\n",
    "    plt.xlim(50, 80)\n",
    "    plt.ylim(62, 77)\n",
    "    plt.title(f'95% prediction interval for the height of a son whose mother is {mom} inches tall: {[np.round(l, 3), np.round(r, 3)]}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def slider_widget():\n",
    "    mom_slider = widgets.IntSlider(value=64, min=50, max=78, step=1, description=\"mom's height\")\n",
    "    ui = widgets.HBox([mom_slider])\n",
    "    out = widgets.interactive_output(pred_interval, {'mom': mom_slider})\n",
    "    display(ui, out)\n",
    "\n",
    "slider_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that **the closer a mother's height is to the mean mother's height, the narrower the prediction interval for her son's height is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Residuals are the errors in the predictions made by the regression line.\n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$\n",
    "- Residual plots help us determine whether a line is a good fit to our data.\n",
    "    - No pattern in residual plot = good linear fit.\n",
    "    - Patterns in residual plot = poor linear fit.\n",
    "    - The correlation coefficient, $r$, doesn't tell the full story! ü¶ñ\n",
    "- To see how our predictions might have been different if we'd had a different sample, bootstrap!\n",
    "    - Resample the data points and make a prediction using the regression line for each resample.\n",
    "    - Many resamples lead to many predictions. Take the middle 95% of them to get a **95% prediction interval**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- We're done with introducing new material!\n",
    "- We'll review in class on Wednesday and Friday."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
