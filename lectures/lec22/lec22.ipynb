{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code,\n",
    "# but make sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "# Animations\n",
    "import time\n",
    "from IPython.display import display, HTML, IFrame, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def normal_curve(x, mu=0, sigma=1):\n",
    "    return 1 / np.sqrt(2*np.pi) * np.exp(-(x - mu)**2/(2 * sigma**2))\n",
    "\n",
    "def normal_area(a, b, bars=False):\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = normal_curve(x)\n",
    "    ix = (x >= a) & (x <= b)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, y, color='black')\n",
    "    plt.fill_between(x[ix], y[ix], color='gold')\n",
    "    if bars:\n",
    "        plt.axvline(a, color='red')\n",
    "        plt.axvline(b, color='red')\n",
    "    plt.title(f'Area between {np.round(a, 2)} and {np.round(b, 2)}')\n",
    "    plt.show()\n",
    "\n",
    "def show_clt_slides():\n",
    "    src = \"https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000&rm=minimal\"\n",
    "    width = 960\n",
    "    height = 509\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 22 – The Normal Distribution, The Central Limit Theorem \n",
    "\n",
    "## DSC 10, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 6 is due on **Saturday 5/27 at 11:59PM**.\n",
    "- Homework 6 – the final homework of the quarter – is due on **Tuesday 5/30 at 11:59PM**.\n",
    "- The Final Project is due on **Tuesday 6/6 at 11:59PM**.\n",
    "- The Grade Report has been updated – take a look on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- The normal distribution.\n",
    "- The Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Standard units\n",
    "\n",
    "SAT scores range from 0 to 1600. The distribution of SAT scores has a mean of 950 and a standard deviation of 300. Your friend tells you that their SAT score, in standard units, is 2.5. What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: The standard normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The standard normal distribution can be thought of as a \"continuous histogram.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like a histogram:\n",
    "    - The **area** between $a$ and $b$ is the **proportion** of values between $a$ and $b$.\n",
    "    - The total area underneath the normal curve is is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: The $x$-axis in a plot of the <u>standard</u> normal distribution is in <u>standard</u> units.**\n",
    "    - For instance, the area between -1 and 1 is the proportion of values within 1 standard deviation of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The standard normal distribution's **cumulative density function** (CDF) describes the proportion of values in the distribution less than or equal to $z$, for all values of $z$.\n",
    "    - In Python, we use the function `scipy.stats.norm.cdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last time, we looked at a data set of heights and weights of 5000 adult males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_and_weight = bpd.read_csv('data/height_and_weight.csv')\n",
    "height_and_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_and_weight.plot(kind='hist', density=True, ec='w', bins=60, alpha=0.8, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Both variables are roughly normal. What _benefit_ is there to knowing that the two distributions are roughly normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Proportion of heights between 65 and 70 inches\n",
    "\n",
    "Let's suppose, as is often the case, that we don't have access to the entire distribution of heights, just the mean and SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heights = height_and_weight.get('Height')\n",
    "height_mean = heights.mean()\n",
    "height_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_std = np.std(heights)\n",
    "height_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just this information, we can estimate the proportion of heights between 65 and 70 inches:\n",
    "\n",
    "1. Convert 65 to standard units.\n",
    "2. Convert 70 to standard units.\n",
    "3. Use `stats.norm.cdf` to find the area between (1) and (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = (65 - height_mean) / height_std\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = (70 - height_mean) / height_std\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "approximation = stats.norm.cdf(right) - stats.norm.cdf(left)\n",
    "approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking the approximation\n",
    "\n",
    "Since we have access to the entire set of heights, we can compute the true proportion of heights between 65 and 70 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True proportion of values between 65 and 70.\n",
    "height_and_weight[\n",
    "    (height_and_weight.get('Height') >= 65) &\n",
    "    (height_and_weight.get('Height') <= 70)\n",
    "].shape[0] / height_and_weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation using the standard normal curve.\n",
    "approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good for an approximation! 🤩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Center and spread, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chebyshev's inequality and the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Last class, we looked at Chebyshev's inequality, which stated that the proportion of values within $z$ SDs of the mean is **at least** $1-\\frac{1}{z^2}$.\n",
    "    - This works for **any** distribution, and is a lower bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we know that the distribution is normal, we can be even more specific!\n",
    "\n",
    "| Range | All Distributions (via Chebyshev's inequality) | Normal Distribution|\n",
    "|---|---|---|\n",
    "| mean $\\pm \\ 1$ SD | $\\geq 0\\%$ |$\\approx 68\\%$ |\n",
    "| mean $\\pm \\ 2$ SDs | $\\geq 75\\%$ | $\\approx 95\\%$ |\n",
    "| mean $\\pm \\ 3$ SDs | $\\geq 88.8\\%$ | $\\approx 99.73\\%$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 68% of values are within 1 SD of the mean\n",
    "\n",
    "Remember, the values on the $x$-axis for the standard normal curve are in standard units. So, the proportion of values within 1 SD of the mean is the area under the standard normal curve between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normal_area(-1, 1, bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(1) - stats.norm.cdf(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if a variable follows a normal distribution, approximately 68% of values will be within 1 SD of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 95% of values are within 2 SDs of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(-2, 2, bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(2) - stats.norm.cdf(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a variable follows a normal distribution, approximately 95% of values will be within 2 SDs of the mean.\n",
    "- Consequently, 5% of values will be outside this range.\n",
    "- Since the normal curve is symmetric, \n",
    "    - 2.5% of values will be more than 2 SDs above the mean, and\n",
    "    - 2.5% of values will be more than 2 SDs below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Proportion of values within $z$ SDs of the mean\n",
    "\n",
    "| Range | All Distributions (via Chebyshev's inequality) | Normal Distribution|\n",
    "|---|---|---|\n",
    "| mean $\\pm \\ 1$ SD | $\\geq 0\\%$ |$\\approx 68\\%$ |\n",
    "| mean $\\pm \\ 2$ SDs | $\\geq 75\\%$ | $\\approx 95\\%$ |\n",
    "| mean $\\pm \\ 3$ SDs | $\\geq 88.8\\%$ | $\\approx 99.73\\%$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The percentages you see for normal distributions above are approximate, but are not lower bounds.\n",
    "\n",
    "**Important**: They apply to all normal distributions, standardized or not. This is because all normal distributions are just stretched and shifted versions of the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inflection points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Last class, we mentioned that the standard normal curve has inflection points at $z = \\pm 1$.\n",
    "    - An inflection point is where a curve goes from \"opening down\" 🙁 to \"opening up\" 🙂."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_area(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We know that the $x$-axis of the standard normal curve represents standard units, so the inflection points are at 1 standard deviation above and below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This means that if a distribution is roughly normal, we can determine its standard deviation by finding the distance between each inflection point and the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Inflection points\n",
    "\n",
    "Remember: The distribution of heights is roughly normal, but it is _not_ a _standard_ normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "height_and_weight.plot(kind='hist', y='Height', density=True, ec='w', bins=40, alpha=0.8, figsize=(10, 5));\n",
    "plt.xticks(np.arange(60, 78, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The center appears to be around 69.\n",
    "- The inflection points appear to be around 66 and 72.\n",
    "- So, the standard deviation is roughly 72 - 69 = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(height_and_weight.get('Height'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back to flight delays ✈️\n",
    "\n",
    "The distribution of flight delays that we've been looking at is _not_ roughly normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = bpd.read_csv('data/delays.csv')\n",
    "delays.plot(kind='hist', y='Delay', bins=np.arange(-20.5, 210, 5), density=True, ec='w', figsize=(10, 5), title='Population Distribution of Flight Delays')\n",
    "plt.xlabel('Delay (minutes)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.get('Delay').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical distribution of a sample statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Before we started discussing center, spread, and the normal distribution, our focus was on bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We used bootstrapping to estimate **the distribution of a sample statistic (e.g. sample mean or sample median)**, using just a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We did this to construct confidence intervals for a population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: For now, we'll suppose our parameter of interest is the population mean, **so we're interested in estimating the distribution of the sample mean**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What we're soon going to discover is a technique for **finding the distribution of the sample mean and creating a confidence interval, without needing to bootstrap**. Think of this as a shortcut to bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical distribution of the sample mean \n",
    "\n",
    "Since we have access to the population of flight delays, let's remind ourselves what the distribution of the sample mean looks like by drawing samples repeatedly from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- This is **not bootstrapping**.\n",
    "- This is also **not practical**. If we had access to a population, we wouldn't need to understand the distribution of the sample mean – we'd be able to compute the population mean directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_means = np.array([])\n",
    "repetitions = 2000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample = delays.sample(500)\n",
    "    sample_mean = sample.get('Delay').mean()\n",
    "    sample_means = np.append(sample_means, sample_mean)\n",
    "    \n",
    "sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(sample_means=sample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.scatter([sample_means.mean()], [-0.005], marker='^', color='green', s=250)\n",
    "plt.axvline(sample_means.mean(), color='green', label=f'mean={np.round(sample_means.mean(), 2)}', linewidth=4)\n",
    "plt.xlim(5, 30)\n",
    "plt.ylim(-0.013, 0.26)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that this distribution is roughly normal, even though the population distribution was not! This distribution is centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Central Limit Theorem\n",
    "\n",
    "> The Central Limit Theorem (CLT) says that the probability distribution of the **sum or mean** of a large random sample drawn with replacement will be roughly normal, regardless of the distribution of the population from which the sample is drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While the formulas we're about to introduce only work for sample means, it's important to remember that the statement above also holds true for sample sums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Characteristics of the distribution of the sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Shape**: The CLT says that the distribution of the sample mean is roughly normal, no matter what the population looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: This distribution is centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: What is the standard deviation of the distribution of the sample mean? How is it impacted by the sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Changing the sample size\n",
    "\n",
    "The function `sample_mean_delays` takes in an integer `sample_size`, and:\n",
    "1. Takes a sample of size `sample_size` directly from the population.\n",
    "2. Computes the mean of the sample.\n",
    "3. Repeats steps 1 and 2 above 2000 times, and returns an array of the resulting means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sample_mean_delays(sample_size):\n",
    "    sample_means = np.array([])\n",
    "    for i in np.arange(2000):\n",
    "        sample = delays.sample(sample_size)\n",
    "        sample_mean = sample.get('Delay').mean()\n",
    "        sample_means = np.append(sample_means, sample_mean)\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's call `sample_mean_delays` on several values of `sample_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample_means = {}\n",
    "sample_sizes = [5, 10, 50, 100, 200, 400, 800, 1600]\n",
    "\n",
    "for size in sample_sizes:\n",
    "    sample_means[size] = sample_mean_delays(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the resulting distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the resulting distributions.\n",
    "bins = np.arange(5, 30, 0.5)\n",
    "for size in sample_sizes:\n",
    "    bpd.DataFrame().assign(data=sample_means[size]).plot(kind='hist', bins=bins, density=True, ec='w', title=f'Distribution of the Sample Mean for Samples of Size {size}', figsize=(8, 4))\n",
    "    plt.legend('');\n",
    "    plt.show()\n",
    "    time.sleep(1.5)\n",
    "    if size != sample_sizes[-1]:\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do you notice? 🤔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard deviation of the distribution of the sample mean\n",
    "\n",
    "- As we increase our sample size, the distribution of the sample mean gets narrower, and so its standard deviation decreases.\n",
    "- Can we determine exactly how much it decreases by?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the standard deviation of each distribution.\n",
    "sds = np.array([])\n",
    "for size in sample_sizes:\n",
    "    sd = np.std(sample_means[size])\n",
    "    sds = np.append(sds, sd)\n",
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "observed = bpd.DataFrame().assign(\n",
    "    SampleSize=sample_sizes,\n",
    "    StandardDeviation=sds\n",
    ")\n",
    "\n",
    "observed.plot(kind='scatter', x='SampleSize', y='StandardDeviation', s=70, title=\"Standard Deviation of the Distribution of the Sample Mean vs. Sample Size\", figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It appears that as the sample size increases, the standard deviation of the distribution of the sample mean _decreases quickly_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard deviation of the distribution of the sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we increase our sample size, the distribution of the sample mean gets narrower, and so its standard deviation decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here's the mathematical relationship describing this phenomenon:\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is sometimes called the **square root law**. Its proof is outside the scope of this class; you'll see it if you take upper-division probability courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This says that when we take large samples, the distribution of the sample mean is narrow, and so the sample mean is typically pretty close to the population mean. As expected, bigger samples tend to yield better estimates of the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Note**: This is **not** saying anything about the standard deviation of a sample itself! It is a statement about the distribution of all possible sample means. If we increase the size of the sample we're taking:\n",
    "    - It **is not true** ❌ that the SD of our sample will decrease.\n",
    "    - It **is true** ✅ that the SD of the distribution of all possible sample means of that size will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Distribution of the sample mean\n",
    "\n",
    "If we were to take many, many samples of the same size from a population, and take the mean of each sample, the distribution of the sample mean will have the following characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Shape**: The distribution will be roughly normal, regardless of the shape of the population distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: The distribution will be centered at the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: The distribution's standard deviation will be described by the square root law: \n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**🚨 Practical Issue**: The mean and standard deviation of the distribution of the sample mean both depend on the original population, but we typically **don't have access to the population**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping vs. the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The goal of bootstrapping was to estimate the distribution of a sample statistic (e.g. the sample mean), given just a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The CLT describes the distribution of the sample mean, but it depends on information about the population (i.e. the population mean and population SD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea**: The sample mean and SD are likely to be close to the population mean and SD. So, use them as approximations in the CLT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As a result, **we can approximate the distribution of the sample mean, given just a single sample, without ever having to bootstrap!**\n",
    "    - In other words, the CLT is a shortcut to bootstrapping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating the distribution of the sample mean by bootstrapping\n",
    "\n",
    "Let's take a single sample of size 500 from `delays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "my_sample = delays.sample(500)\n",
    "my_sample.get('Delay').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before today, to estimate the distribution of the sample mean using just this sample, we'd bootstrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_means = np.array([])\n",
    "repetitions = 2000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    resample = my_sample.sample(500, replace=True)\n",
    "    resample_mean = resample.get('Delay').mean()\n",
    "    resample_means = np.append(resample_means, resample_mean)\n",
    "    \n",
    "resample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(resample_means=resample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.scatter([resample_means.mean()], [-0.005], marker='^', color='green', s=250)\n",
    "plt.axvline(resample_means.mean(), color='green', label=f'mean={np.round(resample_means.mean(), 2)}', linewidth=4)\n",
    "plt.xlim(7, 20)\n",
    "plt.ylim(-0.015, 0.35)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The CLT tells us what this distribution will look like, without having to bootstrap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the CLT with just a single sample\n",
    "\n",
    "Suppose all we have access to in practice is a single \"original sample.\" If we were to take many, many samples of the same size from this original sample, and take the mean of each resample, the distribution of the (re)sample mean will have the following characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Shape**: The distribution will be roughly normal, regardless of the shape of the original sample's distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Center**: The distribution will be centered at the **original sample's mean**, which should be close to the population's mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Spread**: The distribution's standard deviation will be described by the square root law: \n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{SD of Distribution of Possible Sample Means} &= \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}} \\\\\n",
    "&\\approx \\boxed{\\frac{\\textbf{Sample SD}}{\\sqrt{\\text{sample size}}}}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's test this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the CLT with just a single sample\n",
    "\n",
    "Using just the original sample, `my_sample`, we estimate that the distribution of the sample mean has the following mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samp_mean_mean = my_sample.get('Delay').mean()\n",
    "samp_mean_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_mean_sd = np.std(my_sample.get('Delay')) / np.sqrt(my_sample.shape[0])\n",
    "samp_mean_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw a normal distribution with the above mean and standard deviation, and overlay the bootstrapped distribution from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = np.linspace(7, 20)\n",
    "norm_y = normal_curve(norm_x, mu=samp_mean_mean, sigma=samp_mean_sd)\n",
    "bpd.DataFrame().assign(Bootstrapping=resample_means).plot(kind='hist', density=True, ec='w', alpha=0.65, bins=20, figsize=(10, 5));\n",
    "plt.plot(norm_x, norm_y, color='black', linestyle='--', linewidth=4, label='CLT')\n",
    "plt.title('Distribution of the Sample Mean, Using Two Methods')\n",
    "plt.xlim(7, 20)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key takeaway**: Given just a single sample, we can use the CLT to estimate the distribution of the sample mean, **without bootstrapping**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "show_clt_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why?\n",
    "\n",
    "Now, we can make confidence intervals for population means **without needing to bootstrap**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping vs. the CLT\n",
    "\n",
    "Bootstrapping still has its uses!\n",
    "\n",
    "| | Bootstrapping | CLT |\n",
    "| --- | --- | --- |\n",
    "| **Pro** | Works for many sample statistics <br> (mean, median, standard deviation). | Only requires 3 numbers – <br>the sample mean, sample SD, and sample size. |\n",
    "| **Con** | Very computationally expensive (requires drawing many, <br> many samples from the original sample). | Only works for the sample mean (and sum). | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- If a variable is roughly normally distributed, then approximately 68% of its values are within 1 SD of the mean, and approximately 95% of its values are within 2 SDs of the mean.\n",
    "- The Central Limit Theorem (CLT) says that the probability distribution of the **sum or mean** of a large random sample drawn with replacement will be roughly normal, regardless of the distribution of the population from which the sample is drawn.\n",
    "- In the case of the sample mean, the CLT says:\n",
    "    - The distribution of the sample mean is centered at the population mean.\n",
    "    - The SD of the distribution of the sample mean is $\\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- Using the CLT to create confidence intervals.\n",
    "- Using CLT-based confidence intervals for hypothesis tests.\n",
    "- Creating CLT-based confidence intervals for population _proportions_.\n",
    "    - Proportions are means!\n",
    "- Choosing sample sizes.\n",
    "    - We want to construct a confidence interval whose width is at most $w$. How many people should we sample?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
