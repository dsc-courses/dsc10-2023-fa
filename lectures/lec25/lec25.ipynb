{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set up packages for lecture. Don't worry about understanding this code,\n",
    "# but  sure to run it if you're following along.\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# New minimize function (wrapper around scipy.optimize.minimize)\n",
    "from inspect import signature\n",
    "from scipy import optimize\n",
    "\n",
    "def minimize(function):\n",
    "    n_args = len(signature(function).parameters)\n",
    "    initial = np.zeros(n_args)\n",
    "    return optimize.minimize(lambda x: function(*x), initial).x\n",
    "\n",
    "# All of the following code is for visualization.\n",
    "def plot_regression_line(df, x, y, margin=.02):\n",
    "    '''Computes the slope and intercept of the regression line between columns x and y in df (in original units) and plots it.'''\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    \n",
    "    df.plot(kind='scatter', x=x, y=y, s=100, figsize=(10, 5), label='original data')\n",
    "    left = df.get(x).min()*(1 - margin)\n",
    "    right = df.get(x).max()*(1 + margin)\n",
    "    domain = np.linspace(left, right, 10)\n",
    "    plt.plot(domain, m*domain + b, color='orange', label='regression line', lw=4)\n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.legend();\n",
    "    \n",
    "def format_equation(m, b):\n",
    "    if b > 0:\n",
    "        return r'$y = %.2fx + %.2f$' % (m, b)\n",
    "    elif b == 0:\n",
    "        return r'$y = %.2fx' % m\n",
    "    else:\n",
    "        return r'$y = %.2fx %.2f$' % (m, b)\n",
    "    \n",
    "def plot_errors(df, m, b, ax=None):\n",
    "    x = df.get('x')\n",
    "    y = m * x + b\n",
    "    df.plot(kind='scatter', x='x', y='y', s=100, label='original data', ax=ax, figsize=(10, 5) if ax is None else None)\n",
    "    \n",
    "    if ax:\n",
    "        plotter = ax\n",
    "    else:\n",
    "        plotter = plt\n",
    "    \n",
    "    plotter.plot(x, y, color='orange', lw=4)\n",
    "    \n",
    "    for k in np.arange(df.shape[0]):\n",
    "        xk = df.get('x').iloc[k]\n",
    "        yk = np.asarray(y)[k]\n",
    "        if k == df.shape[0] - 1:\n",
    "            plotter.plot([xk, xk], [yk, df.get('y').iloc[k]], linestyle=(0, (1, 1)), c='r', lw=4, label='errors')\n",
    "        else:\n",
    "            plotter.plot([xk, xk], [yk, df.get('y').iloc[k]], linestyle=(0, (1, 1)), c='r', lw=4)\n",
    "    \n",
    "    plt.title(format_equation(m, b), fontsize=18)\n",
    "    plt.xlim(50, 90)\n",
    "    plt.ylim(40, 100)\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 25 ‚Äì Regression and Least Squares\n",
    "\n",
    "## DSC 10, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 7 is due **tomorrow at 11:59 PM**.\n",
    "    - It is true that your lowest lab is dropped.\n",
    "    - However, it's a bad idea to simply ignore this lab, because it's the only assignment on regression, which will be tested on the Final Exam.\n",
    "- The Final Project is due on **Tuesday 6/6 at 11:59PM**.\n",
    "    - Issues saving your Final Project notebook? Watch [this video](https://edstem.org/us/courses/38383/discussion/3158956)!\n",
    "- The Final Exam is on **Saturday, 6/10 from 7-10PM**. More details to come over the weekend, but start prepping by working through old Final Exams at [practice.dsc10.com](https://practice.dsc10.com).\n",
    "    - Take them as if they're a real exam ‚Äì time yourself, and don't use resources other than the reference sheet.\n",
    "- The Grade Report has been updated ‚Äì it reflects your scores on everything other than Lab 7, next week's discussion, the Final Project, and the Final Exam.\n",
    "- Please fill out CAPEs! We will have an internal End-of-Quarter survey as well, to be released this weekend.\n",
    "- The application to be a DSC 10 tutor in the fall has been released! The application can be found [here](https://academicaffairs.ucsd.edu/Modules/ASES/Apply.aspx?cid=5210), and more information can be found [here](https://datascience.ucsd.edu/current-students/dsc-tutors/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- The regression line in standard units.\n",
    "- The regression line in original units.\n",
    "- Outliers.\n",
    "- Errors in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The regression line in standard units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting heights  üë™ üìè\n",
    "\n",
    "Recall, in the last lecture, we aimed to use a mother's height to predict her adult son's height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = bpd.read_csv('data/galton.csv')\n",
    "male_children = galton[galton.get('gender') == 'male']\n",
    "mom_son = bpd.DataFrame().assign(mom = male_children.get('mother'), \n",
    "                                 son = male_children.get('childHeight'))\n",
    "mom_son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_son.plot(kind='scatter', x='mom', y='son', figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation\n",
    "\n",
    "Recall, the correlation coefficient $r$ of two variables $x$ and $y$ is defined as the \n",
    "- **average** value of the \n",
    "- **product** of $x$ and $y$\n",
    "- when both are measured in **standard units**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert a sequence of numbers to standard units.\"\n",
    "    return (any_numbers - any_numbers.mean()) / np.std(any_numbers)\n",
    "\n",
    "def correlation(df, x, y):\n",
    "    \"Computes the correlation between column x and column y of df.\"\n",
    "    return (standard_units(df.get(x)) * standard_units(df.get(y))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mom_son = correlation(mom_son, 'mom', 'son')\n",
    "r_mom_son"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line\n",
    "\n",
    "- The regression line is the line through $(0,0)$ with slope $r$, when both variables are measured in **standard units**.\n",
    "\n",
    "<center><img src='data/regression-line.png' width=30%></center>\n",
    "\n",
    "- We use the regression line to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: If a mother's height is 0.5 SDs above the average mother's height, and $r = 0.32$, our prediction is that her son's height will be $0.5 \\cdot 0.32 = 0.16$ SDs above the average son's height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: To use this form of the regression line, we need to know mothers' heights in standard units, but it would be more convenient to think in terms of inches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The regression line in original units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "Each time we wanted to predict the height of an adult son given the height of his mother, we had to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Convert the mother's height from inches to standard units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Multiply by the correlation coefficient to predict the son's height in standard units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Convert the son's predicted height from standard units back to inches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is inconvenient ‚Äì wouldn't it be great if we could express the regression line itself in inches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From standard units to original units\n",
    "\n",
    "When $x$ and $y$ are in standard units, the regression line is given by\n",
    "\n",
    "<center><img src='data/regression-line.png' width=30%></center>\n",
    "\n",
    "What is the regression line when $x$ and $y$ are in their original units (e.g. inches)?\n",
    "\n",
    "<center><img src=\"data/original_standard.png\" width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line in original units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can work backwards from the relationship\n",
    "$$\\text{predicted } y_{\\text{(su)}} = r \\cdot x_{\\text{(su)}}$$\n",
    "to find the line in original units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\frac{\\text{predicted } y - \\text{mean of }y}{\\text{SD of }y} = r \\cdot \\frac{x - \\text{mean of } x}{\\text{SD of }x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $r, \\text{mean of } x$, $\\text{mean of } y$, $\\text{SD of } x$, and $\\text{SD of } y$ are constants ‚Äì if you have a DataFrame with two columns, you can determine all 5 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Re-arranging the above equation into the form $\\text{predicted } y = mx + b$ yields the formulas:\n",
    "\n",
    "$$\\boxed{m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}, \\: \\: b = \\text{mean of } y - m \\cdot \\text{mean of } x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $m$ is the slope of the regression line and $b$ is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's implement these formulas in code and try them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def slope(df, x, y):\n",
    "    \"Returns the slope of the regression line between columns x and y in df (in original units).\"\n",
    "    r = correlation(df, x, y)\n",
    "    return r * np.std(df.get(y)) / np.std(df.get(x))\n",
    "\n",
    "def intercept(df, x, y):\n",
    "    \"Returns the intercept of the regression line between columns x and y in df (in original units).\"\n",
    "    return df.get(y).mean() - slope(df, x, y) * df.get(x).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compute the slope and intercept of the regression line between mothers' heights and sons' heights (in inches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heights = slope(mom_son, 'mom', 'son')\n",
    "m_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_heights = intercept(mom_son, 'mom', 'son')\n",
    "b_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, the regression line is\n",
    "\n",
    "$$\\text{predicted son's height in inches} = 0.365 \\cdot \\text{mother's height in inches} + 45.858$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict_son(mom):\n",
    "    return m_heights * mom + b_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's the predicted height of a son whose mother is 62 inches tall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if the mother is 55 inches tall? 73 inches tall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_son(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(57, 72)\n",
    "ys = predict_son(xs)\n",
    "mom_son.plot(kind='scatter', x='mom', y='son', figsize=(10, 5), title='Regression line predictions, in original units', label='original data');\n",
    "plt.plot(xs, ys, color='orange', lw=4, label='regression line')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The effect of outliers on correlation\n",
    "\n",
    "Consider the dataset below. What is the correlation between $x$ and $y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = bpd.read_csv('data/outlier.csv')\n",
    "outlier.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "correlation(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Removing the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_outlier = outlier[outlier.get('y') > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "correlation(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Takeaway**: Even a single outlier can have a massive impact on the correlation, and hence the regression line. Look for these before performing regression. **Always visualize first!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Errors in prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've presented the regression line in standard units as the line through the origin with slope $r$, given by $\\text{predicted } y_{\\text{(su)}} = r \\cdot x_{\\text{(su)}}$. Then, we used this equation to find a formula for the regression line in original units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In examples we've seen so far, the regression line seems to fit our data pretty well.\n",
    "    - But how well? \n",
    "    - What makes the regression line good?\n",
    "    - Would another line be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Without the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_no_outlier = slope(without_outlier, 'x', 'y')\n",
    "b_no_outlier = intercept(without_outlier, 'x', 'y')\n",
    "\n",
    "m_no_outlier, b_no_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(without_outlier, m_no_outlier, b_no_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We think our regression line is pretty good because most data points are pretty close to the regression line. The red lines are quite short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measuring the error in prediction\n",
    "\n",
    "$$\\text{error} = \\text{actual value} - \\text{prediction}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A good prediction line is one where the errors tend to be small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To measure the rough size of the errors, for a particular set of predictions:\n",
    "    1. Square the errors so that they don't cancel each other out.\n",
    "    2. Take the mean of the squared errors.\n",
    "    3. Take the square root to fix the units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is called **root mean square error** (RMSE).\n",
    "    - Notice the similarities to computing the SD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error (RMSE) of the regression line's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's compute the regression line's predictions for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = m_no_outlier * without_outlier.get('x') + b_no_outlier\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To find the RMSE, we need to start by finding the errors and squaring them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors.\n",
    "without_outlier.get('y') - predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared errors.\n",
    "(without_outlier.get('y') - predicted_y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, we need to find the mean of the squared errors, and take the square root of that. The result is the RMSE of the regression line's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error.\n",
    "((without_outlier.get('y') - predicted_y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error.\n",
    "np.sqrt(((without_outlier.get('y') - predicted_y) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The RMSE of the regression line's predictions is about 2.2. Is this big or small, relative to the predictions of other lines? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error (RMSE) in an arbirtrary line's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've been using the regression line to make predictions. But we could use a different line!\n",
    "    - To make a prediction for `x` using an arbitrary line defined by `slope` and `intercept`, compute `x * slope + intercept`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For this dataset, if we choose a **different line**, we will end up with different predictions, and hence a **different RMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(slope, intercept):\n",
    "    '''Calculates the RMSE of the line with the given slope and intercept, \n",
    "    using the 'x' and 'y' columns of without_outlier.'''\n",
    "\n",
    "    # The true values of y.\n",
    "    true = without_outlier.get('y')\n",
    "    \n",
    "    # The predicted values of y, from plugging the x values from the \n",
    "    # given DataFrame into the line with the given slope and intercept.\n",
    "    predicted = slope * without_outlier.get('x') + intercept\n",
    "    \n",
    "    return np.sqrt(((true - predicted) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that our function works on the regression line.\n",
    "rmse(m_no_outlier, b_no_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's compute the RMSEs of several different lines on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Experiment by changing one of these!\n",
    "lines = [(1.2, -15), (0.75, 11.5), (-0.4, 100)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 4))\n",
    "for i, line in enumerate(lines):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    m, b = line\n",
    "    plot_errors(without_outlier, m, b, ax=ax[i])\n",
    "    ax[i].set_title(format_equation(m, b) + f'\\nRMSE={np.round(rmse(m, b), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the \"best\" prediction line by minimizing RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- RMSE describes how well a line fits the data. **The lower the RMSE of a line is, the better it fits the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are infinitely many slopes and intercepts, and thus infinitely many RMSEs. How do we find which combination of slope and intercept have the lowest RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If you take DSC 40A, you'll learn how to do this using calculus. For now, we'll use a function that can do it automatically ‚Äì `minimize`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The function `minimize` takes in a function as an argument, and returns the inputs to the function that produce the smallest output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, we know that the minimizing input to the function $f(x) = (x - 5)^2 + 4$ is $x = 5$. `minimize` can find this, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x - 5) ** 2 + 4\n",
    "\n",
    "# Plot of f(x).\n",
    "x = np.linspace(0, 10)\n",
    "y = f(x)\n",
    "plt.plot(x, y)\n",
    "plt.title(r'$f(x) = (x - 5)^2 + 4$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The `minimize` function uses calculus and intelligent trial-and-error to find these inputs; you don't need to know how it works under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the \"best\" prediction line by minimizing RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `minimize` on `rmse`, to find the slope and intercept of the line with the smallest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_rmse_line = minimize(rmse)\n",
    "smallest_rmse_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do these numbers look familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coincidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slope and intercept with the smallest RMSE, from our call to minimize.\n",
    "m_smallest_rmse = smallest_rmse_line[0]\n",
    "b_smallest_rmse = smallest_rmse_line[1]\n",
    "m_smallest_rmse, b_smallest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slope and intercept according to our regression line formulas.\n",
    "slope(without_outlier, 'x', 'y'), intercept(without_outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slopes and intercepts we got using both approaches look awfully similar... üëÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression line is the best line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It turns out that the regression line we defined before before minimizes the root mean squared error (RMSE) among all lines.\n",
    "\n",
    "$$m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}$$\n",
    "\n",
    "$$b = \\text{mean of } y - m \\cdot \\text{mean of } x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is the **best** line, regardless of what our data looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- All equivalent names:\n",
    "    - Line of ‚Äúbest fit‚Äù.\n",
    "    - Least squares line.\n",
    "    - Regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The technique of finding the slope and intercept that have the lowest RMSE is called the **method of least squares**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quality of fit\n",
    "\n",
    "- The regression line describes the \"best linear fit\" for a given dataset.\n",
    "- The formulas for the slope and intercept work no matter what the shape of the data is.\n",
    "- But the line is only meaningful if the relationship between $x$ and $y$ is roughly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Non-linear data\n",
    "\n",
    "What's the regression line for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "x2 = bpd.DataFrame().assign(\n",
    "    x=np.arange(-6, 6.1, 0.5) + np.random.normal(size=25), \n",
    "    y=np.arange(-6, 6.1, 0.5)**2 + np.random.normal(size=25)\n",
    ")\n",
    "x2.plot(kind='scatter', x='x', y='y', s=100, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_line(x2, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line doesn't fit the data at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Any set of predictions has _errors_.\n",
    "\n",
    "$$\\text{error} = \\text{actual } y - \\text{predicted } y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- When using the regression line to make predictions, the errors are called **residuals**.\n",
    "     \n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There is one residual corresponding to each data point $(x, y)$ in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The regression line in original units is $\\text{predicted } y = mx + b$, where\n",
    "\n",
    "$$m = r \\cdot \\frac{\\text{SD of } y}{\\text{SD of }x}$$\n",
    "\n",
    "$$b = \\text{mean of } y - m \\cdot \\text{mean of } x$$\n",
    "- This line is very sensitive to outliers.\n",
    "- This line has the lowest root mean squared error (RMSE) of all possible lines.\n",
    "    - It is the \"line of best fit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- As we saw, the regression line is the best *line* to fit the data, but not all data is linear. \n",
    "- How do we determine whether fitting a line even makes sense for our dataset?\n",
    "- When we use regression, we're making predictions based on data in a sample. What if we had a different sample?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
